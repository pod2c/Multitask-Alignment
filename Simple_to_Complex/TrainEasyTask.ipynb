{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41e1c000-38a6-4dc0-91dc-a320807d2443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q -U transformers accelerate datasets bitsandbytes einops wandb trl peft scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5208ba-fb3e-484c-9d22-3efdca83a035",
   "metadata": {},
   "source": [
    "# 分别导入imdb的训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9208fa4-0cc4-4d0f-b904-c317452eefa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 加载sciq数据集的训练集和测试集\n",
    "train_dataset = load_dataset(\"imdb\", split=\"train\")\n",
    "test_dataset = load_dataset(\"imdb\", split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935e01c8-17c0-473a-8d3a-36071ed30ca4",
   "metadata": {},
   "source": [
    "# 打乱训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79de48ce-69b0-4066-9f59-5c89f9e2ad62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d335a020-e4d9-417b-aede-c7078f013b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "train_data = train_dataset.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fc31b6e-3324-46f2-b3ff-bea48504d8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'VIVAH in my opinion is the best movie of 2006, coming from a director that has proved successful throughout his career. I am not too keen in romantic movies these days, because i see them as \"old wine in a new bottle\" and so predictable. However, i have watched this movie three times now...and believe me it\\'s an awesome movie.<br /><br />VIVAH goes back to the traditional route, displaying simple characters into a sensible and realistic story of the journey between engagement and marriage. The movie entertains in all manners as it can be reflected to what we do (or would do) when it comes to marriage. In that sense Sooraj R. Barjatya has done his homework well and has depicted a very realistic story into a well-made highly entertaining movie.<br /><br />Several sequences in this movie catch your interest immediately: <br /><br />* When Shahid Kapoor comes to see the bride (Amrita Rao) - the way he tries to look at her without making it too obvious in front of his and her family. The song \\'Do Anjaane Ajnabi\\' goes well with the mood of this scene.<br /><br />* The first conversation between Shahid and Amrita, when he comes to see her - i.e. a shy Shahid not knowing exactly what to talk about but pulling of a decent conversation. Also Amrita\\'s naive nature, limited eye-contact, shy characteristics and answering softly to Shahid\\'s questions.<br /><br />* The emotional breakdown of Amrita and her uncle (Alok Nath) when she feeds him at Shahid\\'s party in the form of another\\'s daughter-in-law rather than her uncle\\'s beloved niece.<br /><br />Clearly the movie belongs to Amrita Rao all the way. The actress portrays the role of Poonam with such conviction that you cannot imagine anybody else replacing her. She looks beautiful throughout the whole movie, and portrays an innocent and shy traditional girl perfectly.<br /><br />Shahid Kapoor performs brilliantly too. He delivers a promising performance and shows that he is no less than Salman Khan when it comes to acting in a Sooraj R. Barjatya film. In fact Shahid and Amrita make a cute on-screen couple, without a shadow of doubt. Other characters - Alok Nath (Excellent), Anupam Kher (Brilliant), Mohan Joshi (Very good).<br /><br />On the whole, VIVAH delivers what it promised, a well made and realistic story of two families. The movie has top-notch performances, excellent story and great music to suit the film, as well as being directed by the fabulous Sooraj R. Barjatya. It\\'s a must see!',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e049c5-62bc-42aa-985a-d9bb1f263efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从原始数据集中随机抽取10000条数据\n",
    "train_data = train_data.shuffle(seed=42).select(range(10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beba5889-6f67-4a44-a008-189bd353de59",
   "metadata": {},
   "source": [
    "# 处理用来训练的训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e5754cf-1f9f-4d85-a7e5-d6a9d865e10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将txt和label字段合并为一个整体\n",
    "def merge_fields(example):\n",
    "    text = example['text']\n",
    "    label = example['label']\n",
    "    merged_input = f\"Text: {text}\\nLabel: {label}\"\n",
    "    return {'merged_input': merged_input}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eb9ae0e-c763-4684-995e-675dfcc02cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18bf15ddad424af9ae56005bc2845db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = train_data.map(merge_fields, remove_columns=['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40a99108-5f96-4d2d-a798-65c054f0d956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'merged_input': 'Text: Gregory Peck\\'s brilliant portrayal of Douglas MacArthur from the Battle of Corregidor in the Philippines at the start of the Pacific War largely through to his removal as UN Commander during the Korean War offers reason to believe all three of the above possibilities. Certainly the most controversial American General of the Second World War (and possibly ever) MacArthur is presented here as a man of massive contradictions. He claims that soldiers above all yearn for peace, yet he obviously glories in war; he consistently denies any political ambitions, yet almost everything he does is deliberately used to boost himself as a presidential candidate; he obviously believes that soldiers under his command have to follow his orders to the letter, yet he himself deliberately defies orders from the President of the United States; he shows great respect for other cultures (particularly in the Philippines and Japan) and yet is completely out of touch with his own country. All these things are held in balance throughout this movie, and in the end the viewer is left to draw his or her own conclusions about the man, although one is left with no doubt that MacArthur sincerely and passionately loved his country, and especially the Army he devoted his life to.<br /><br />Peck\\'s performance was, as I said, brilliant - to the point, actually, of overshadowing virtually everyone else in the film (which is perhaps appropriate, given who he was portraying!) with the possible exception of Ed Flanders. I though he offered a compelling look at Harry Truman and his attitude to MacArthur: sarcastic (repeatedly referring to MacArthur as \"His Majesty,\") angry, frustrated and finally completely fed up with this General who simply won\\'t respect his authority as President. Marj Dusay was also intriguing as MacArhur\\'s wife Jean, devoted to her husband (whom she herself referred to as \"General,\" although their relationship seems to have been a happy enough one.) I very much enjoyed this movie, although perhaps would have liked to have learned a little more about MacArthur\\'s early life. I have always chuckled at MacArthur\\'s reaction to Eisenhower being elected President (\"He\\'ll make a fine President - he was the best damn clerk I ever had\" - which seems to sum up what MacArthur thought the role of the President should be, especially to his military commanders during wartime.) Well worth watching. 8/10\\nLabel: 1'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24753637-a2a8-4645-b98c-78fd59f3cf95",
   "metadata": {},
   "source": [
    "# 导入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "064e9385-96f3-48e4-9dcb-369df720d626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f087ad5297f4f7bbdba5544771e4a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "model_name = 'llama3'\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map='auto',\n",
    "    trust_remote_code=True,\n",
    "    #num_labels=2\n",
    ")\n",
    "model.config.use_cache = False\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5771e1-5811-49ae-b20b-165e919eabeb",
   "metadata": {},
   "source": [
    "# 设置训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5321cf5a-e5e3-4cc5-9d3e-f5d8c9d61289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "output_dir = './results'\n",
    "per_device_train_batch_size = 4\n",
    "gradient_accumulation_steps = 4\n",
    "optim = 'paged_adamw_32bit'\n",
    "save_steps = 1000\n",
    "logging_steps = 10\n",
    "learning_rate = 2e-5\n",
    "max_grad_norm = 0.3\n",
    "max_steps = 1000\n",
    "warmup_ratio = 0.03\n",
    "lr_scheduler_type = 'constant'\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ecf953-adcf-4f3a-b80d-8144b46cb373",
   "metadata": {},
   "source": [
    "# 设置训练器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5aac7a9f-2b75-4d41-a4e3-6deb2310ef12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1965: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:269: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:307: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f21e96508ab24360bf4c116d0da325b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "max_seq_length = 512\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    dataset_text_field='merged_input',\n",
    "    #label_field='label',\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")\n",
    "\n",
    "for name, module in trainer.model.named_modules():\n",
    "    if 'norm' in name:\n",
    "        module = module.to(torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d59e82-d667-47d3-aaf0-0ca5d29cb557",
   "metadata": {},
   "source": [
    "# 模型训练阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e41be5-6a62-45c5-8a7b-0f3493bb2d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms1820587\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/wandb/run-20240624_121758-nutiziwp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s1820587/huggingface/runs/nutiziwp' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/s1820587/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s1820587/huggingface' target=\"_blank\">https://wandb.ai/s1820587/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s1820587/huggingface/runs/nutiziwp' target=\"_blank\">https://wandb.ai/s1820587/huggingface/runs/nutiziwp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   2/1875 : < :, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "401cd78f-9abc-47bd-87a1-ad1420c3aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\n",
    "model_to_save.save_pretrained('finetuned_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5d9658e-3084-402b-9629-455ef6841d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model and tokenizer saved to multitask_model\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "# 保存训练好的模型\n",
    "output_dir = \"multitask_model\"\n",
    "model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "print(f\"Trained model and tokenizer saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b93fdd-28dd-4c98-9ea9-14017f4d71b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
